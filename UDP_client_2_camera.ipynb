{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c2fd5c-e4ab-4dd5-b369-1925af915c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 17:34:01.777736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-30 17:34:01.795941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-30 17:34:01.801244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-30 17:34:01.858607: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mifm3dpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m O3D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# MAKING ASYNC MULTIPROCESS VERSION\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# from IPython import display\n",
    "\n",
    "import time\n",
    "from lib_xml_tree import *\n",
    "from lib_connection import *\n",
    "from lib_robot_transformations import *\n",
    "from lib_config_loader import load_config\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from utils import label_map_util\n",
    "\n",
    "import json\n",
    "from ifm3dpy.device import O3D\n",
    "# import argparse\n",
    "from pathlib import Path\n",
    "import copy, socket\n",
    "\n",
    "import cv2                #  assumed – for AprilTag detection\n",
    "import numpy as np\n",
    "from ifm3dpy.pcic import FrameGrabber, buffer_id\n",
    "import subprocess, logging\n",
    "from typing import Tuple\n",
    "from calib_routine import optimize \n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CameraManager:\n",
    "    def __init__(self, cfg, rx_queue, tx_queue):\n",
    "        self.cfg = cfg     \n",
    "        self._rx_q = rx_queue # robot → calib thread\n",
    "        self._tx_q = tx_queue # calib thread → robot\n",
    "        \n",
    "        self.state = \"free\" # free / calibration / inference / loading_weights / loading parameters \n",
    "        self.model = None\n",
    "        self.detect_fn = None\n",
    "        self.mode = \"inference\"   # inference / calibration\n",
    "\n",
    "        self.o3d = O3D(ip=self.cfg[\"SENSOR_IP\"])\n",
    "        self._config_path = None  # path to the settings file of current settings\n",
    "        self._config = None       # current camera settings config, read from self._config_path  \n",
    "        \n",
    "\n",
    "        # prepare to work\n",
    "        self.set_inference_settings()\n",
    "      \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def load_model(self):\n",
    "        # Load saved model and build the detection function\n",
    "        self.model = tf.saved_model.load(self.cfg['PATH_TO_SAVED_MODEL'])\n",
    "        self.detect_fn = self.model.signatures['serving_default']\n",
    "\n",
    "    def calib_procedure(self):\n",
    "\n",
    "        ################################################ \n",
    "        # # what to expect in received_dict from robot\n",
    "        # sent_mess_list.append({\"Sen\" : {'Type' : 'ServerToCamera'}})    \n",
    "        # sent_mess_list.append({\"WatchDog_out\" : watchDog_out})  \n",
    "        # sent_mess_list.append({'Frame_assigned': frame_assigned})\n",
    "        # sent_mess_list.append({'Position_reached': position_reached})\n",
    "        # sent_mess_list.append({'Need_cam_cal': need_cam_cal})\n",
    "        # sent_mess_list.append({'Screenshot': screenshot}) \n",
    "        ################################################\n",
    "        # what to send to the robot\n",
    "        # msg: dict[str, object] = {\n",
    "        # \"Sen\":        {\"Type\": \"Camera\"},\n",
    "        # \"XYZ1\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "        # \"XYZ2\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "        # \"XYZ3\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "        # \"XYZ4\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "        # \"CAM_CAL_RES\":{\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\",\n",
    "        #                \"A\": \"0.0\", \"B\": \"0.0\", \"C\": \"0.0\"},\n",
    "        # \"WatchDog_in\":     watchDog_out,\n",
    "        # \"Frame_assign\":    \"0\",\n",
    "        # \"Move_next_pt\":    \"0\",\n",
    "        # \"Cam_cal_in_proc\": \"0\",\n",
    "        # \"See_4_targets\":   \"0\",\n",
    "        ################################################\n",
    "        try:            \n",
    "            self.mode  = \"calibration\"\n",
    "            self.set_calibration_settings()\n",
    "            self.state = \"busy\"\n",
    "\n",
    "            ################################################\n",
    "            # calibration logic\n",
    "            # data collection\n",
    "            \n",
    "            cam_frames_list = []\n",
    "            rob_frames_list = []\n",
    "            \n",
    "            self.send_robot({\"Cam_cal_in_proc\": '1'})  # robot <-- camera_manager\n",
    "            self.wait_robot(\"Position_reached\", '1')  # robot --> camera_manager\n",
    "            \n",
    "            for _ in range(self.cfg[\"num_calib_positions\"]):              \n",
    "                self.send_robot({\"Move_next_pt\": '1'})     # robot <-- camera_manager\n",
    "                self.wait_robot(\"Position_reached\", '0') # robot --> camera_manager\n",
    "                self.send_robot({\"Move_next_pt\": '0'})     # robot <-- camera_manager\n",
    "    \n",
    "                self.wait_robot(\"Need_cam_cal\", '1')      # robot --> camera_manager\n",
    "                self.wait_robot(\"Position_reached\", '1')  # robot --> camera_manager\n",
    "                \n",
    "                r = self.wait_robot(\"DEF_RIst\", None) # robot --> camera_manager\n",
    "                rob_frames_list.append([float(r[key]) for key in ['X','Y','Z','A','B','C']])\n",
    "                \n",
    "                T, timetag = self.capture_apriltag_transform() # make a screenshot  T = np.matrix [4,4]\n",
    "                rob_frames_list.append(Rotation_matrix(T, \"KUKA\").extract_frame().to_list())\n",
    "                \n",
    "            # optimization\n",
    "            result_dict = optimize(cam_frames_list, rob_frames_list)\n",
    "            self.send_robot({\"CAM_CAL_RES\": result_dict})   # robot <-- camera_manager\n",
    "            self.send_robot({\"Frame_assign\": '1'})          # robot <-- camera_manager\n",
    "            self.wait_robot(\"Frame_assigned\", '1')          # robot --> camera_manager\n",
    "            self.send_robot({\"Frame_assign\": '0'})          # robot <-- camera_manager\n",
    "            self.wait_robot(\"Need_cam_cal\", '0')            # robot --> camera_manager\n",
    "            self.send_robot({\"Cam_cal_in_proc\": '0'})       # robot <-- camera_manager\n",
    "            \n",
    "            ################################################\n",
    "            \n",
    "            self.set_inference_settings()\n",
    "        finally:                \n",
    "            self.mode  = \"inference\"\n",
    "            self.state = \"free\"\n",
    "\n",
    "        return result_kuka_frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- private helpers ----------\n",
    "    @staticmethod\n",
    "    def _load_config_file(path: Path) -> dict:\n",
    "        \"\"\"Load configuration from disk into a Python dict.\"\"\"\n",
    "        with open(path, \"r\", encoding=\"utf‑8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def _push_config(self) -> None:\n",
    "        \"\"\"Send the current `self._config` JSON to the camera.\"\"\"\n",
    "        self.o3d.from_json(self._config)\n",
    "\n",
    "    def _pull_config(self) -> None:\n",
    "        \"\"\"Fetch the live configuration from the camera into memory (`self._config`).\"\"\"\n",
    "        self._config = self.o3d.to_json()\n",
    "\n",
    "    # ---------- public API ----------\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Return a **deep copy** of the current config so the caller can’t modify it in place.\"\"\"\n",
    "        return copy.deepcopy(self._config)\n",
    "\n",
    "    def save_config_to_file(self, path: str | Path | None = None) -> None:\n",
    "        \"\"\"Persist the working configuration to disk.\"\"\"\n",
    "        path = Path(path or self._config_path)\n",
    "        with open(path, \"w\", encoding=\"utf‑8\") as f:\n",
    "            json.dump(self._config, f, indent=2)\n",
    "\n",
    "    def update_config(self, patch: dict, push: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Apply a *patch* to the working config and, optionally,\n",
    "        push the result to the camera immediately.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        patch : dict\n",
    "            Keys/values to merge into the current configuration.\n",
    "            Nested dictionaries are merged recursively.\n",
    "        push : bool, default=True\n",
    "            If *True*, call `_push_config()` after merging.\n",
    "        \"\"\"\n",
    "        # Recursively merge nested dictionaries\n",
    "        def merge(a: dict, b: dict) -> None:\n",
    "            for k, v in b.items():\n",
    "                if isinstance(v, dict) and isinstance(a.get(k), dict):\n",
    "                    merge(a[k], v)\n",
    "                else:\n",
    "                    a[k] = v\n",
    "\n",
    "        merge(self._config, patch)\n",
    "        if push:\n",
    "            self._push_config()\n",
    "\n",
    "    def reload_from_device(self) -> None:\n",
    "        \"\"\"Sync the local copy if someone changed the camera settings directly on the device.\"\"\"\n",
    "        self._pull_config()\n",
    "\n",
    "    def set_calibration_settings(self) -> None:\n",
    "        \"\"\"Load calibration JSON and push it to the camera.\"\"\"\n",
    "        self.state = 'changing settings to calibration'\n",
    "        \n",
    "        cfg_path = Path(self.cfg[\"config_path_calibration_setting\"]).expanduser().resolve()\n",
    "        assert cfg_path.is_file(), f\"Calibration file not found: {cfg_path}\"\n",
    "    \n",
    "        self._config_path = cfg_path                  \n",
    "        self._config = self._load_config_file(cfg_path)\n",
    "        self._push_config()\n",
    "\n",
    "        wait_camera_online(self.cfg[\"SENSOR_IP\"])  # await for camera alive again\n",
    "        self.mode = \"calibration\"   # inference / calibration\n",
    "        self.state = \"free\"\n",
    "        print(\"Calibration settings applied.\")\n",
    "    \n",
    "    def set_inference_settings(self) -> None:        \n",
    "        \"\"\"Load inference JSON and push it to the camera.\"\"\"\n",
    "        self.state = 'changing settings to inference'\n",
    "        \n",
    "        cfg_path = Path(self.cfg[\"config_path_work_inference_setting\"]).expanduser().resolve()\n",
    "        assert cfg_path.is_file(), f\"Inference file not found: {cfg_path}\"\n",
    "    \n",
    "        self._config_path = cfg_path                   \n",
    "        self._config = self._load_config_file(cfg_path)\n",
    "        self._push_config()\n",
    "\n",
    "        wait_camera_online(self.cfg[\"SENSOR_IP\"])  # await for camera alive again\n",
    "        self.mode = \"inference\"   # inference / calibration\n",
    "        self.state = \"free\"\n",
    "        print(\"Inference settings applied.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def wait_camera_online(ip: str, *, timeout: float = 10.0, interval: float = 0.5) -> None:\n",
    "        \"\"\"\n",
    "        Blocking subproced while camera is rebooting\n",
    "        await for camera ping feedback of timeout\n",
    "        Makes RuntimeError, if no response from camera within timeout .\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "        while True:\n",
    "            #   -c 1  : послать 1 пакет\n",
    "            #   -W 1  : ждать ответа 1 секунду\n",
    "            if subprocess.call([\"ping\", \"-c\", \"1\", \"-W\", \"1\", ip],\n",
    "                               stdout=subprocess.DEVNULL,\n",
    "                               stderr=subprocess.DEVNULL) == 0:\n",
    "                logging.info(\"Camera %s is back online (%.1f s)\", ip, time.time() - t0)\n",
    "                return\n",
    "    \n",
    "            if time.time() - t0 > timeout:\n",
    "                raise RuntimeError(f\"Camera {ip} did not come online in {timeout} s\")\n",
    "    \n",
    "            time.sleep(interval)\n",
    "\n",
    "\n",
    "    def wait_robot(self, field: str, desired_value : bool, timeout: float | None = None):\n",
    "        \"\"\"field = 'Position_reached'  – safely extract specific sig from robot telegram in background process\"\"\"\n",
    "        end = time.time() + timeout if timeout else None\n",
    "        while True:\n",
    "            try:\n",
    "                msg = self._rx_q.get(timeout=timeout)\n",
    "            except Empty:\n",
    "                return None\n",
    "            dic = extract_xml(msg)\n",
    "            if field in dic and (dic[field] == desired_value or desired_value is None):\n",
    "                return dic[field]\n",
    "            if end:\n",
    "                timeout = max(0, end - time.time())\n",
    "\n",
    "   \n",
    "    def send_robot(self, patch: dict):\n",
    "        \"\"\"patch = {'Cam_cal_in_proc': '1'}  – include new sig into telegram to the robot\"\"\"\n",
    "        self._tx_q.put(patch)\n",
    "\n",
    "    async def capture_apriltag_transform(\n",
    "        self,\n",
    "        *,\n",
    "        save_raw: bool = False,\n",
    "        root_dir: Path = Path(self.cfg[\"root_dir\"]),\n",
    "        timeout_ms: int = 100,\n",
    "    ) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Grab one frame by SW‑trigger, find an AprilTag, and return the 4×4\n",
    "        homogeneous transform (camera → tag).\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        save_raw : bool, default=False\n",
    "            If *True* the amplitude / distance / confidence / XYZ buffers are\n",
    "            saved on disk under `root_dir/YYYY_MM_DD/{AM|PM}/{index}/`.\n",
    "        root_dir : Path\n",
    "            Top‑level folder for raw dumps (ignored when `save_raw` == False).\n",
    "        timeout_ms : int\n",
    "            `FrameGrabber.wait_for_frame()` timeout.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        transform : np.ndarray  [4, 4]\n",
    "        timestamp : float        Unix epoch (s)\n",
    "    \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            When the camera is unreachable or no AprilTag is detected.\n",
    "        \"\"\"\n",
    "    \n",
    "        loop = asyncio.get_running_loop()\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 1. Prepare helpers that must NOT block the asyncio loop\n",
    "        # -----------------------------------------------------------------\n",
    "        def _ping(ip: str, tries: int = 1) -> bool:\n",
    "            \"\"\"True if the device replies to ICMP.\"\"\"\n",
    "            cmd = [\"ping\", \"-c\", str(tries), \"-W\", \"1\", ip]\n",
    "            return subprocess.call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) == 0\n",
    "    \n",
    "        def _open_fg() -> FrameGrabber:\n",
    "            \"\"\"Create and start a new frame grabber.\"\"\"\n",
    "            cam = self.o3d                                 # already opened in __init__\n",
    "            fg_ = FrameGrabber(cam, pcic_port=self.cfg[\"xmlrpc_port\"])\n",
    "            fg_.start([\n",
    "                buffer_id.AMPLITUDE_IMAGE,\n",
    "                buffer_id.RADIAL_DISTANCE_IMAGE,\n",
    "                buffer_id.CONFIDENCE_IMAGE,\n",
    "                buffer_id.XYZ,\n",
    "            ])\n",
    "            return fg_\n",
    "    \n",
    "        def _normalize_amplitude(buf: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"Stretch uint16 → uint8 for debugging / storage.\"\"\"\n",
    "            arr = buf.copy()\n",
    "            arr[arr >= 16200] = 0          # device‑specific cut‑off\n",
    "            arr[:, 215:] = 0              # mask right margin\n",
    "            mn, mx = arr.min(), arr.max()\n",
    "            return ((arr - mn) * 255 / max(mx - mn, 1)).astype(np.uint8)\n",
    "    \n",
    "        def _detect(buf_amp: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "            \"\"\"\n",
    "            AprilTag detection stub.\n",
    "            Returns (corner_px[4,2], transform_cam_tag[4,4]).\n",
    "            Replace this with your real detector.\n",
    "            \"\"\"\n",
    "            # Dummy detector: always fails\n",
    "            raise RuntimeError(\"No AprilTag detected\")\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 2. (Re)open the frame grabber – done in a thread\n",
    "        # -----------------------------------------------------------------\n",
    "        fg = await loop.run_in_executor(None, _open_fg)\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 3. Try to trigger & grab a frame (with basic retry)\n",
    "        # -----------------------------------------------------------------\n",
    "        for attempt in range(2):          # two shots: first may time out\n",
    "            try:\n",
    "                fg.sw_trigger()\n",
    "                ok, frame = fg.wait_for_frame().wait_for(timeout_ms)\n",
    "            except Exception as exc:\n",
    "                logging.warning(\"Frame grabber error: %s\", exc)\n",
    "                ok = False\n",
    "    \n",
    "            if ok:\n",
    "                break\n",
    "    \n",
    "            # Frame failed – check if the device is alive\n",
    "            ip = self.cfg[\"SENSOR_IP\"]\n",
    "            alive = await loop.run_in_executor(None, _ping, ip)\n",
    "            if not alive:\n",
    "                raise RuntimeError(f\"Camera {ip} is unreachable (ping failed)\")\n",
    "            await asyncio.sleep(0.1)      # give the sensor a moment\n",
    "    \n",
    "        if not ok:\n",
    "            raise RuntimeError(\"Timeout while waiting for a frame\")\n",
    "    \n",
    "        ts_epoch = frame.timestamps().image_time_ns / 1e9\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 4. Process the buffers (runs in executor to keep event‑loop free)\n",
    "        # -----------------------------------------------------------------\n",
    "        def _post_process():\n",
    "            buf_amp  = frame.get_buffer(buffer_id.AMPLITUDE_IMAGE)\n",
    "            buf_dist = frame.get_buffer(buffer_id.RADIAL_DISTANCE_IMAGE)\n",
    "            buf_conf = frame.get_buffer(buffer_id.CONFIDENCE_IMAGE)\n",
    "            buf_xyz  = frame.get_buffer(buffer_id.XYZ)          # shape (H,W,3)\n",
    "    \n",
    "            amp_u8 = _normalize_amplitude(buf_amp)\n",
    "    \n",
    "            corners_px, T_cam_tag = _detect(amp_u8)\n",
    "    \n",
    "            if save_raw:\n",
    "                # Build folder  …/YYYY_MM_DD/AM|PM/N/\n",
    "                now       = datetime.datetime.now()\n",
    "                day_dir   = root_dir / now.strftime(\"%Y_%m_%d\") / now.strftime(\"%p\")\n",
    "                index_dir = max([int(p.name) for p in day_dir.iterdir() if p.is_dir()] + [0]) + 1\n",
    "                dump_dir  = day_dir / f\"{index_dir:04d}\"\n",
    "                dump_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "                base = dump_dir / now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "                np.save(base.with_suffix(\"_xyz.npy\"), buf_xyz)\n",
    "                cv2.imwrite(str(base.with_suffix(\"_amp.png\")),  amp_u8)\n",
    "                cv2.imwrite(str(base.with_suffix(\"_dist.png\")), buf_dist)\n",
    "                cv2.imwrite(str(base.with_suffix(\"_conf.png\")), buf_conf)\n",
    "    \n",
    "            return T_cam_tag\n",
    "    \n",
    "        T = await loop.run_in_executor(None, _post_process)\n",
    "        return T, ts_epoch\n",
    "        \n",
    "\n",
    "async def main():\n",
    "    # Load IP, PORT configuration from config\n",
    "    config = load_config()\n",
    "    target_address = config['clients']['camera']['target_address']  \n",
    "    target_port = config['clients']['camera']['target_port']\n",
    " \n",
    "    # Create socket\n",
    "    UDPClientSocket = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)\n",
    "    server_address =  (target_address, target_port)\n",
    "\n",
    "    # CREATE CameraManager object\n",
    "    rx_queue = Queue()    # robot → calib thread\n",
    "    tx_queue = Queue()    # calib thread → robot\n",
    "    cm = CameraManager(cfg = config['camera_manager'], rx_queue=rx_queue, tx_queue=tx_queue)\n",
    "    cm.load_model()\n",
    "\n",
    "    # PREPARE CHILDREN SUBROCESS POOL\n",
    "    loop = asyncio.get_running_loop()\n",
    "    executor = ThreadPoolExecutor()\n",
    "\n",
    "    \n",
    "    # PREPARE TO START LOOP\n",
    "    telegram = create_xml_fast([{'IPOC': '0'}])\n",
    "    print('start_mess = :', telegram)\n",
    "    # init dependant telegram variables\n",
    "    watchDog_out = '0'\n",
    "    proc = None\n",
    "    thread = None\n",
    "\n",
    "    cfg_future: asyncio.Future | None = None     # перед while True # background process handler\n",
    "    while True:\n",
    "        ################################################\n",
    "        # SENDING MESSAGES TO CAMERA SERVER-SUBPROCESS\n",
    "        ################################################  \n",
    "        TransmitData = telegram\n",
    "        SendData(TransmitData, UDPClientSocket, server_address)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        ################################################\n",
    "        # RECEIVING MESSAGES FROM CAMERA SERVER-SUBPROCESS\n",
    "        ################################################ \n",
    "        bytesAddressPair = UDPClientSocket.recvfrom(4096)\n",
    "\n",
    "        # ----------  put robot telegram into calibration stream ------------\n",
    "        if cfg_future and not cfg_future.done():  # only when calibration is going on\n",
    "            rx_queue.put_nowait(raw_msg)          # <── for calib thread\n",
    "        # ------------------------------------------------ ------------    \n",
    "\n",
    "        ReceivedMessage = bytesAddressPair[0]\n",
    "        address = bytesAddressPair[1]\n",
    "        # clientMsg = \"Message from Client:{}\".format(ReceivedMessage)\n",
    "        # clientIP = \"Client IP Address:{}\".format(address)\n",
    "        #print(clientMsg)\n",
    "        #print(clientIP)\n",
    "        received_dict = extract_xml(ReceivedMessage)\n",
    "        ##print('camera_received_telegram', ReceivedMessage)\n",
    "\n",
    "        # use received data from cam\n",
    "        try:\n",
    "            watchDog_out = received_dict['WatchDog_out']\n",
    "        except Exception as ex:\n",
    "            print(f\" Data can not be extracted from received to camera telegram: {ex}\")   \n",
    "\n",
    "        ################################################\n",
    "        # MAIN OPERATION LOGIC\n",
    "        ################################################ \n",
    "        # RUN HEAVY TASK IN BACKGROUND MODE\n",
    "\n",
    "        # --- Start a background switch --------------------------------\n",
    "        if received_dict['need_cam_cal'] == \"1\" and cm.mode == \"inference\" and cm.state == \"free\" and cfg_future is None:\n",
    "            cfg_future = loop.run_in_executor(None, cm.calib_procedure)\n",
    "            logging.info(\"Started calibration\")\n",
    "\n",
    "        # --- Check if the calibration has finished -------------------------\n",
    "        if cfg_future and cfg_future.done():\n",
    "            try:\n",
    "                calibration_frame = cfg_future.result()          # propagate exceptions\n",
    "                logging.info(f\"Camera calibration executed successfully, frame: {calibration_frame}\")\n",
    "            except Exception as exc:\n",
    "                logging.error(\"Camera calibration failed: %s\", exc)                \n",
    "            finally:\n",
    "                cfg_future = None            # ready for the next request\n",
    "\n",
    "\n",
    "        if received_dict['need_cam_cal'] == \"0\" and cm.mode == \"inference\" and cm.state == \"free\":\n",
    "            # DO INFERENCE. SYNC or ASYNC\n",
    "\n",
    "        ################################################\n",
    "        # END OF MAIN OPERATION LOGIC\n",
    "        ################################################ \n",
    "        # # what to expect in received_dict from robot\n",
    "        # sent_mess_list.append({\"Sen\" : {'Type' : 'ServerToCamera'}})    \n",
    "        # sent_mess_list.append({\"WatchDog_out\" : watchDog_out})  \n",
    "        # sent_mess_list.append({'Frame_assigned': frame_assigned})\n",
    "        # sent_mess_list.append({'Position_reached': position_reached})\n",
    "        # sent_mess_list.append({'Need_cam_cal': need_cam_cal})\n",
    "        # sent_mess_list.append({'Screenshot': screenshot}) \n",
    "\n",
    "        ################################################\n",
    "        # PREPARING THE MESSAGE TO BE SENT\n",
    "        ################################################ \n",
    "        msg: dict[str, object] = {\n",
    "            \"Sen\":        {\"Type\": \"Camera\"},\n",
    "            \"XYZ1\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "            \"XYZ2\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "            \"XYZ3\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "            \"XYZ4\":       {\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\"},\n",
    "            \"CAM_CAL_RES\":{\"X\": \"0.0\", \"Y\": \"0.0\", \"Z\": \"0.0\",\n",
    "                           \"A\": \"0.0\", \"B\": \"0.0\", \"C\": \"0.0\"},\n",
    "            \"WatchDog_in\":     watchDog_out,\n",
    "            \"Frame_assign\":    \"0\",\n",
    "            \"Move_next_pt\":    \"0\",\n",
    "            \"Cam_cal_in_proc\": \"0\",\n",
    "            \"See_4_targets\":   \"0\",\n",
    "        }\n",
    "        \n",
    "        # ----------  apply signals from calibration stream ------------\n",
    "        if cfg_future and not cfg_future.done(): # only when calibration\n",
    "            while True:\n",
    "                try:\n",
    "                    patch = tx_queue.get_nowait()     # patch: dict[str, Any]\n",
    "                except Empty:\n",
    "                    break\n",
    "                msg.update(patch)                     \n",
    "        \n",
    "        # ----------  convert into needed format --------------------------\n",
    "        sent_mess_list = [{k: v} for k, v in msg.items()]\n",
    "        \n",
    "        telegram = create_xml_fast(sent_mess_list)\n",
    "        \n",
    "                \n",
    "        #display.clear_output(wait=True)\n",
    "        await asyncio.sleep(0.001) # DO NOT CHANGE\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    await main() # TO USE IN  JUPYTER NITEBOOK ONLY\n",
    "    #asyncio.run(main()) # TO USE IN SCRIPT, NOT JUPYTER NITEBOOK\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39e891-b66d-42ec-8135-16b9ee9cadef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053adfba-24d2-43c7-a703-3dec7f1595bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2edc6-6d1b-4518-82db-426ba54d18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
